"""
EPS Momentum Dashboard â€” FastAPI Backend

Reads from the EPS Momentum SQLite database and serves screening,
portfolio, and analytics data via REST endpoints.
"""

import os
import sqlite3
from contextlib import contextmanager
from typing import Optional

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware

# ---------------------------------------------------------------------------
# Configuration
# ---------------------------------------------------------------------------

DB_PATH = os.environ.get(
    "EPS_DB_PATH",
    os.path.join(os.path.dirname(os.path.abspath(__file__)), "..", "..", "eps-momentum-us", "eps_momentum_data.db"),
)

app = FastAPI(title="EPS Momentum Dashboard API", version="0.1.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ---------------------------------------------------------------------------
# INDUSTRY_MAP  (copied from eps_momentum_system.py)
# ---------------------------------------------------------------------------

INDUSTRY_MAP = {
    # Technology
    'Semiconductors': 'ë°˜ë„ì²´',
    'Semiconductor Equipment & Materials': 'ë°˜ë„ì²´ìž¥ë¹„',
    'Software - Application': 'ì‘ìš©SW',
    'Software - Infrastructure': 'ì¸í”„ë¼SW',
    'Information Technology Services': 'ITì„œë¹„ìŠ¤',
    'Computer Hardware': 'HW',
    'Electronic Components': 'ì „ìžë¶€í’ˆ',
    'Scientific & Technical Instruments': 'ê³„ì¸¡ê¸°ê¸°',
    'Communication Equipment': 'í†µì‹ ìž¥ë¹„',
    'Consumer Electronics': 'ê°€ì „',
    'Electronics & Computer Distribution': 'ì „ìžìœ í†µ',
    'Electronic Gaming & Multimedia': 'ê²Œìž„',
    'Solar': 'íƒœì–‘ê´‘',
    # Internet & Media
    'Internet Content & Information': 'ì¸í„°ë„·',
    'Internet Retail': 'ì˜¨ë¼ì¸ìœ í†µ',
    'Entertainment': 'ì—”í„°',
    'Broadcasting': 'ë°©ì†¡',
    'Publishing': 'ì¶œíŒ',
    'Advertising Agencies': 'ê´‘ê³ ',
    'Telecom Services': 'í†µì‹ ',
    # Financial
    'Banks - Regional': 'ì§€ì—­ì€í–‰',
    'Banks - Diversified': 'ëŒ€í˜•ì€í–‰',
    'Asset Management': 'ìžì‚°ìš´ìš©',
    'Capital Markets': 'ìžë³¸ì‹œìž¥',
    'Credit Services': 'ì‹ ìš©ì„œë¹„ìŠ¤',
    'Financial Data & Stock Exchanges': 'ê¸ˆìœµë°ì´í„°',
    'Insurance - Property & Casualty': 'ì†í•´ë³´í—˜',
    'Insurance - Life': 'ìƒëª…ë³´í—˜',
    'Insurance - Diversified': 'ì¢…í•©ë³´í—˜',
    'Insurance - Specialty': 'íŠ¹ìˆ˜ë³´í—˜',
    'Insurance - Reinsurance': 'ìž¬ë³´í—˜',
    'Insurance Brokers': 'ë³´í—˜ì¤‘ê°œ',
    'Financial Conglomerates': 'ê¸ˆìœµì§€ì£¼',
    # Healthcare
    'Medical Devices': 'ì˜ë£Œê¸°ê¸°',
    'Medical Instruments & Supplies': 'ì˜ë£Œìš©í’ˆ',
    'Medical Care Facilities': 'ì˜ë£Œì‹œì„¤',
    'Medical Distribution': 'ì˜ì•½ìœ í†µ',
    'Diagnostics & Research': 'ì§„ë‹¨ì—°êµ¬',
    'Drug Manufacturers - General': 'ëŒ€í˜•ì œì•½',
    'Drug Manufacturers - Specialty & Generic': 'íŠ¹ìˆ˜ì œì•½',
    'Biotechnology': 'ë°”ì´ì˜¤',
    'Healthcare Plans': 'ê±´ê°•ë³´í—˜',
    'Health Information Services': 'ì˜ë£Œì •ë³´',
    # Industrials
    'Aerospace & Defense': 'ë°©ì‚°',
    'Specialty Industrial Machinery': 'ì‚°ì—…ê¸°ê³„',
    'Farm & Heavy Construction Machinery': 'ì¤‘ìž¥ë¹„',
    'Engineering & Construction': 'ê±´ì„¤',
    'Building Products & Equipment': 'ê±´ì¶•ìžìž¬',
    'Building Materials': 'ê±´ìžìž¬',
    'Electrical Equipment & Parts': 'ì „ê¸°ìž¥ë¹„',
    'Tools & Accessories': 'ê³µêµ¬',
    'Industrial Distribution': 'ì‚°ì—…ìœ í†µ',
    'Specialty Business Services': 'ë¹„ì¦ˆë‹ˆìŠ¤ì„œë¹„ìŠ¤',
    'Consulting Services': 'ì»¨ì„¤íŒ…',
    'Security & Protection Services': 'ë³´ì•ˆ',
    'Waste Management': 'íê¸°ë¬¼',
    'Pollution & Treatment Controls': 'í™˜ê²½',
    'Conglomerates': 'ë³µí•©ê¸°ì—…',
    'Integrated Freight & Logistics': 'ë¬¼ë¥˜',
    'Railroads': 'ì² ë„',
    'Trucking': 'íŠ¸ëŸ­ìš´ì†¡',
    'Airlines': 'í•­ê³µ',
    'Marine Shipping': 'í•´ìš´',
    'Rental & Leasing Services': 'ë Œíƒˆë¦¬ìŠ¤',
    # Consumer Cyclical
    'Auto Parts': 'ìžë™ì°¨ë¶€í’ˆ',
    'Auto Manufacturers': 'ìžë™ì°¨',
    'Auto & Truck Dealerships': 'ìžë™ì°¨ë”œëŸ¬',
    'Restaurants': 'ì™¸ì‹',
    'Specialty Retail': 'ì „ë¬¸ì†Œë§¤',
    'Discount Stores': 'í• ì¸ì ',
    'Home Improvement Retail': 'í™ˆì¸í…Œë¦¬ì–´',
    'Apparel Retail': 'ì˜ë¥˜ì†Œë§¤',
    'Apparel Manufacturing': 'ì˜ë¥˜ì œì¡°',
    'Department Stores': 'ë°±í™”ì ',
    'Footwear & Accessories': 'ì‹ ë°œìž¡í™”',
    'Luxury Goods': 'ëª…í’ˆ',
    'Residential Construction': 'ì£¼íƒê±´ì„¤',
    'Furnishings, Fixtures & Appliances': 'ê°€êµ¬ê°€ì „',
    'Resorts & Casinos': 'ë¦¬ì¡°íŠ¸ì¹´ì§€ë…¸',
    'Gambling': 'ë„ë°•',
    'Lodging': 'ìˆ™ë°•',
    'Travel Services': 'ì—¬í–‰',
    'Recreational Vehicles': 'ë ˆì €ì°¨ëŸ‰',
    'Leisure': 'ë ˆì €',
    'Personal Services': 'ìƒí™œì„œë¹„ìŠ¤',
    # Consumer Defensive
    'Packaged Foods': 'ì‹í’ˆ',
    'Beverages - Non-Alcoholic': 'ìŒë£Œ',
    'Beverages - Brewers': 'ë§¥ì£¼',
    'Beverages - Wineries & Distilleries': 'ì£¼ë¥˜',
    'Confectioners': 'ì œê³¼',
    'Household & Personal Products': 'ìƒí™œìš©í’ˆ',
    'Tobacco': 'ë‹´ë°°',
    'Grocery Stores': 'ì‹ë£Œí’ˆì ',
    'Food Distribution': 'ì‹í’ˆìœ í†µ',
    'Education & Training Services': 'êµìœ¡',
    # Real Estate
    'REIT - Specialty': 'ë¦¬ì¸ íŠ¹ìˆ˜',
    'REIT - Residential': 'ë¦¬ì¸ ì£¼ê±°',
    'REIT - Retail': 'ë¦¬ì¸ ì†Œë§¤',
    'REIT - Industrial': 'ë¦¬ì¸ ì‚°ì—…',
    'REIT - Healthcare Facilities': 'ë¦¬ì¸ ì˜ë£Œ',
    'REIT - Office': 'ë¦¬ì¸ ì˜¤í”¼ìŠ¤',
    'REIT - Hotel & Motel': 'ë¦¬ì¸ í˜¸í…”',
    'REIT - Mortgage': 'ë¦¬ì¸ ëª¨ê¸°ì§€',
    'REIT - Diversified': 'ë¦¬ì¸ ë³µí•©',
    'Real Estate Services': 'ë¶€ë™ì‚°ì„œë¹„ìŠ¤',
    # Energy
    'Oil & Gas E&P': 'ì„ìœ ê°€ìŠ¤',
    'Oil & Gas Midstream': 'ì„ìœ ë¯¸ë“œìŠ¤íŠ¸ë¦¼',
    'Oil & Gas Equipment & Services': 'ì„ìœ ìž¥ë¹„',
    'Oil & Gas Refining & Marketing': 'ì„ìœ ì •ì œ',
    'Oil & Gas Integrated': 'ì„ìœ ì¢…í•©',
    # Utilities
    'Utilities - Regulated Electric': 'ì „ë ¥',
    'Utilities - Regulated Gas': 'ê°€ìŠ¤',
    'Utilities - Regulated Water': 'ìˆ˜ë„',
    'Utilities - Diversified': 'ìœ í‹¸ë³µí•©',
    'Utilities - Independent Power Producers': 'ë…ë¦½ë°œì „',
    'Utilities - Renewable': 'ì‹ ìž¬ìƒ',
    # Basic Materials
    'Specialty Chemicals': 'íŠ¹ìˆ˜í™”í•™',
    'Chemicals': 'í™”í•™',
    'Agricultural Inputs': 'ë†ì—…',
    'Steel': 'ì² ê°•',
    'Aluminum': 'ì•Œë£¨ë¯¸ëŠ„',
    'Copper': 'êµ¬ë¦¬',
    'Gold': 'ê¸ˆ',
    'Other Precious Metals & Mining': 'ê·€ê¸ˆì†',
    'Other Industrial Metals & Mining': 'ì‚°ì—…ê¸ˆì†',
    'Lumber & Wood Production': 'ëª©ìž¬',
    'Metal Fabrication': 'ê¸ˆì†ê°€ê³µ',
    'Packaging & Containers': 'í¬ìž¥ìž¬',
    'Farm Products': 'ë†ì‚°ë¬¼',
    # Other
    'N/A': 'ê¸°íƒ€',
}

# Reverse lookup: ticker -> industry would require yfinance at runtime.
# The DB does NOT store industry, so industry_distribution in /api/stats
# will be unavailable unless we add that column.  For now we return an
# empty dict and note the limitation.

# ---------------------------------------------------------------------------
# Database helpers
# ---------------------------------------------------------------------------


@contextmanager
def get_db():
    """Yield a sqlite3 connection with row_factory set."""
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    try:
        yield conn
    finally:
        conn.close()


def rows_to_dicts(rows):
    """Convert sqlite3.Row objects to plain dicts."""
    return [dict(r) for r in rows]


def _get_columns(conn, table: str) -> set[str]:
    """Return the set of column names for a table."""
    cur = conn.execute(f"PRAGMA table_info({table})")
    return {r["name"] for r in cur.fetchall()}


# ---------------------------------------------------------------------------
# Business-logic helpers
# ---------------------------------------------------------------------------


def calc_segments(ntm_current, ntm_7d, ntm_30d, ntm_60d, ntm_90d):
    """4 independent segment change rates, capped +/-100%."""
    def pct(new, old):
        if old is None or old == 0:
            return 0.0
        return max(-100.0, min(100.0, ((new - old) / abs(old)) * 100))

    seg1 = pct(ntm_current, ntm_7d)    # 7d -> today
    seg2 = pct(ntm_7d, ntm_30d)        # 30d -> 7d
    seg3 = pct(ntm_30d, ntm_60d)       # 60d -> 30d
    seg4 = pct(ntm_60d, ntm_90d)       # 90d -> 60d
    return seg1, seg2, seg3, seg4


def trend_icon(pct_val: float) -> str:
    if pct_val > 20:
        return "\U0001f525"     # ðŸ”¥
    elif pct_val >= 5:
        return "\u2600\ufe0f"   # â˜€ï¸
    elif pct_val >= 1:
        return "\U0001f324\ufe0f"  # ðŸŒ¤ï¸
    elif pct_val >= -1:
        return "\u2601\ufe0f"   # â˜ï¸
    else:
        return "\U0001f327\ufe0f"  # ðŸŒ§ï¸


def _get_last_n_part2_dates(conn, n: int = 3) -> list[str]:
    """Return the last *n* distinct dates that have part2_rank data, newest first."""
    cur = conn.execute(
        "SELECT DISTINCT date FROM ntm_screening "
        "WHERE part2_rank IS NOT NULL "
        "ORDER BY date DESC LIMIT ?",
        (n,),
    )
    return [r["date"] for r in cur.fetchall()]


def _compute_3day_status(ticker: str, dates: list[str], ticker_dates_map: dict) -> str:
    """
    dates: last 3 dates, newest first.
    ticker_dates_map: {ticker: set_of_dates_where_it_had_part2_rank}
    """
    present = ticker_dates_map.get(ticker, set())
    if len(dates) >= 3 and all(d in present for d in dates[:3]):
        return "\u2705"  # âœ…
    if len(dates) >= 2 and all(d in present for d in dates[:2]):
        return "\u23f3"  # â³
    return "\U0001f195"  # ðŸ†•


def _build_ticker_dates_map(conn, dates: list[str]) -> dict:
    """Build {ticker: set(dates)} for the given dates where part2_rank IS NOT NULL."""
    if not dates:
        return {}
    placeholders = ",".join("?" for _ in dates)
    cur = conn.execute(
        f"SELECT ticker, date FROM ntm_screening "
        f"WHERE part2_rank IS NOT NULL AND date IN ({placeholders})",
        dates,
    )
    result: dict[str, set] = {}
    for r in cur.fetchall():
        result.setdefault(r["ticker"], set()).add(r["date"])
    return result


def _build_rank_history(ticker: str, dates: list[str], conn) -> str:
    """Return e.g. '3->4->1' for last 3 dates (oldest->newest)."""
    if not dates:
        return ""
    # dates are newest-first; reverse to oldest-first for display
    ordered = list(reversed(dates))
    placeholders = ",".join("?" for _ in ordered)
    cur = conn.execute(
        f"SELECT date, part2_rank FROM ntm_screening "
        f"WHERE ticker = ? AND part2_rank IS NOT NULL AND date IN ({placeholders})",
        [ticker] + ordered,
    )
    rank_by_date = {r["date"]: r["part2_rank"] for r in cur.fetchall()}
    parts = []
    for d in ordered:
        r = rank_by_date.get(d)
        parts.append(str(r) if r is not None else "-")
    return "\u2192".join(parts)  # arrow â†’


# ---------------------------------------------------------------------------
# Endpoints
# ---------------------------------------------------------------------------


@app.get("/api/health")
def health():
    """Health check."""
    db_exists = os.path.isfile(DB_PATH)
    return {"status": "ok", "db_exists": db_exists, "db_path": DB_PATH}


@app.get("/api/dates")
def list_dates():
    """List all available dates (those with part2_rank data), newest first."""
    with get_db() as conn:
        cur = conn.execute(
            "SELECT DISTINCT date FROM ntm_screening "
            "WHERE part2_rank IS NOT NULL "
            "ORDER BY date DESC"
        )
        return [r["date"] for r in cur.fetchall()]


@app.get("/api/screening/{date}")
def get_screening(date: str):
    """Top 30 candidates for a specific date, enriched with segments and status."""
    with get_db() as conn:
        cols = _get_columns(conn, "ntm_screening")
        # Base columns always present
        select_cols = [
            "ticker", "part2_rank", "score", "adj_score", "adj_gap",
            "price", "ma60", "ntm_current", "ntm_7d", "ntm_30d", "ntm_60d", "ntm_90d",
            "rev_up30", "rev_down30", "num_analysts", "is_turnaround",
        ]
        # Optional columns (may not exist in older DBs)
        optional = [
            "composite_rank", "rev_growth", "market_cap", "roe",
            "debt_to_equity", "operating_margin", "free_cashflow", "beta",
        ]
        for c in optional:
            if c in cols:
                select_cols.append(c)
        # Fetch rows for the requested date
        cur = conn.execute(
            f"SELECT {','.join(select_cols)} "
            "FROM ntm_screening WHERE date = ? AND part2_rank IS NOT NULL "
            "ORDER BY part2_rank ASC",
            (date,),
        )
        rows = rows_to_dicts(cur.fetchall())
        if not rows:
            return []

        # 3-day status context
        last3 = _get_last_n_part2_dates(conn, 3)
        td_map = _build_ticker_dates_map(conn, last3)

        for row in rows:
            # Segments
            seg1, seg2, seg3, seg4 = calc_segments(
                row.get("ntm_current") or 0,
                row.get("ntm_7d") or 0,
                row.get("ntm_30d") or 0,
                row.get("ntm_60d") or 0,
                row.get("ntm_90d") or 0,
            )
            row["seg1"] = round(seg1, 2)
            row["seg2"] = round(seg2, 2)
            row["seg3"] = round(seg3, 2)
            row["seg4"] = round(seg4, 2)

            # Trend icons (seg4 -> seg1 = past -> present)
            row["trend"] = (
                trend_icon(seg4) + trend_icon(seg3) + trend_icon(seg2) + trend_icon(seg1)
            )

            # 3-day verification status
            row["status_3d"] = _compute_3day_status(row["ticker"], last3, td_map)

            # Rank history
            row["rank_history"] = _build_rank_history(row["ticker"], last3, conn)

        return rows


@app.get("/api/portfolio/{date}")
def get_portfolio(date: str):
    """Portfolio log entries for a specific date."""
    with get_db() as conn:
        cur = conn.execute(
            "SELECT date, ticker, action, price, weight, "
            "entry_date, entry_price, exit_price, return_pct "
            "FROM portfolio_log WHERE date = ? ORDER BY ticker",
            (date,),
        )
        return rows_to_dicts(cur.fetchall())


@app.get("/api/portfolio/history")
def get_portfolio_history():
    """Full portfolio history grouped by date."""
    with get_db() as conn:
        cur = conn.execute(
            "SELECT date, ticker, action, price, weight, "
            "entry_date, entry_price, exit_price, return_pct "
            "FROM portfolio_log ORDER BY date DESC, ticker"
        )
        rows = rows_to_dicts(cur.fetchall())

    # Group by date
    grouped: dict[str, list] = {}
    for r in rows:
        grouped.setdefault(r["date"], []).append(r)
    return grouped


@app.get("/api/ticker/{ticker}")
def get_ticker_history(ticker: str):
    """Historical screening data for a single ticker."""
    with get_db() as conn:
        cols = _get_columns(conn, "ntm_screening")
        select_cols = ["date", "score", "adj_score", "adj_gap", "price", "ma60",
                       "ntm_current", "part2_rank"]
        for c in ["composite_rank", "rev_growth"]:
            if c in cols:
                select_cols.append(c)
        cur = conn.execute(
            f"SELECT {','.join(select_cols)} "
            "FROM ntm_screening WHERE ticker = ? ORDER BY date",
            (ticker.upper(),),
        )
        return rows_to_dicts(cur.fetchall())


@app.get("/api/stats/{date}")
def get_stats(date: str):
    """Screening statistics for a date."""
    with get_db() as conn:
        # Total screened
        total_screened = conn.execute(
            "SELECT COUNT(*) as cnt FROM ntm_screening WHERE date = ?", (date,)
        ).fetchone()["cnt"]

        # Eligible (adj_score > 9)
        total_eligible = conn.execute(
            "SELECT COUNT(*) as cnt FROM ntm_screening WHERE date = ? AND adj_score > 9",
            (date,),
        ).fetchone()["cnt"]

        # Top 30
        top30_count = conn.execute(
            "SELECT COUNT(*) as cnt FROM ntm_screening WHERE date = ? AND part2_rank IS NOT NULL",
            (date,),
        ).fetchone()["cnt"]

        # 3-day status counts
        last3 = _get_last_n_part2_dates(conn, 3)
        td_map = _build_ticker_dates_map(conn, last3)

        # Get tickers in today's Top 30
        cur = conn.execute(
            "SELECT ticker FROM ntm_screening WHERE date = ? AND part2_rank IS NOT NULL",
            (date,),
        )
        today_tickers = [r["ticker"] for r in cur.fetchall()]

        verified_count = 0
        new_count = 0
        for t in today_tickers:
            st = _compute_3day_status(t, last3, td_map)
            if st == "\u2705":
                verified_count += 1
            elif st == "\U0001f195":
                new_count += 1

        # Industry distribution â€” DB does not store industry column,
        # so this will be empty.  If you add an 'industry' column to
        # ntm_screening in the future, this section can be populated.
        industry_distribution: dict[str, int] = {}

        return {
            "date": date,
            "total_screened": total_screened,
            "total_eligible": total_eligible,
            "top30_count": top30_count,
            "verified_count": verified_count,
            "new_count": new_count,
            "industry_distribution": industry_distribution,
        }


@app.get("/api/exited/{date}")
def get_exited(date: str):
    """
    Death list: stocks that were in yesterday's Top 30 but dropped out today.
    Returns each exited ticker with yesterday's rank.
    """
    with get_db() as conn:
        # Find the date immediately before 'date' that has part2_rank data
        cur = conn.execute(
            "SELECT DISTINCT date FROM ntm_screening "
            "WHERE part2_rank IS NOT NULL AND date < ? "
            "ORDER BY date DESC LIMIT 1",
            (date,),
        )
        prev_row = cur.fetchone()
        if prev_row is None:
            return []
        prev_date = prev_row["date"]

        # Yesterday's Top 30
        cur = conn.execute(
            "SELECT ticker, part2_rank FROM ntm_screening "
            "WHERE date = ? AND part2_rank IS NOT NULL",
            (prev_date,),
        )
        yesterday = {r["ticker"]: r["part2_rank"] for r in cur.fetchall()}

        # Today's Top 30
        cur = conn.execute(
            "SELECT ticker FROM ntm_screening "
            "WHERE date = ? AND part2_rank IS NOT NULL",
            (date,),
        )
        today_set = {r["ticker"] for r in cur.fetchall()}

        # Exited
        exited = []
        for ticker, rank in sorted(yesterday.items(), key=lambda x: x[1]):
            if ticker not in today_set:
                exited.append({
                    "ticker": ticker,
                    "prev_date": prev_date,
                    "prev_rank": rank,
                })

        return exited


# ---------------------------------------------------------------------------
# Entry point
# ---------------------------------------------------------------------------

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)
